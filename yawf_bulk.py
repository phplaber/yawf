#!/usr/bin/env python3

import os
import sys
import re
import time
import json
import copy
import base64
import optparse
from urllib.parse import urlparse, parse_qsl, unquote
from xml.etree import ElementTree as ET

from core.fuzzer import Fuzzer
from utils.utils import (
    check_file,
    send_request,
    parse_conf,
    read_file,
    get_content_type,
    get_default_headers,
    is_base64,
    Browser,
    OOBDetector
)
from utils.constants import REQ_TIMEOUT, MARK_POINT, UA, PROBE, PLATFORM, EFFICIENCY_CONF

if __name__ == '__main__':

    # 记录启动时间
    start_time = int(time.time())

    parser = optparse.OptionParser()
    parser.add_option("-f", dest="requests_file", help="Full requests dump, generated by browser crawler")
    parser.add_option("--output-dir", dest="output_dir", help="Custom output directory path")
    parser.add_option("--oob-provider", dest="oob_provider", default="ceye", help="Out-of-Band service provider, default: ceye (e.g. dnslog)")
    options, _ = parser.parse_args()

    # 必需 -f 选项
    if not options.requests_file or not check_file(options.requests_file):
        parser.error('option -f must be set and readable')

    # 校验 oob 服务
    oob_provider = options.oob_provider.lower()
    if oob_provider not in ['dnslog', 'ceye']:
        sys.exit('[*] Only support dnslog and ceye provider')

    # 自动标记忽略的参数集合
    ignore_params = EFFICIENCY_CONF.get('ignore_params')

    # 脚本相对目录
    script_rel_dir = os.path.dirname(sys.argv[0])

    # 解析配置文件
    conf_dict = parse_conf(os.path.join(script_rel_dir, 'yawf.conf'))
    if not conf_dict:
        sys.exit('[*] parse config file error')
    
    # 网络代理
    proxies = {
        'http': conf_dict['request_proxy'], 
        'https': conf_dict['request_proxy']
    } if conf_dict['request_proxy'] else {}
    
    # 请求超时时间（秒）
    timeout = float(conf_dict['request_timeout']) if conf_dict['request_timeout'] else REQ_TIMEOUT

    user_agent = conf_dict['request_user_agent'] if conf_dict['request_user_agent'] else UA

    # 获取探针
    probes = []
    if conf_dict['probe_customize']:
        if 'all' in conf_dict['probe_customize']:
            # 全部探针
            files = next(os.walk(os.path.join(script_rel_dir, 'core', 'probes')), (None, None, []))[2]
            probes = [os.path.splitext(f)[0] for f in files if not f.startswith('__init__')]
        else:
            probes = [probe.strip() for probe in conf_dict['probe_customize'].split(',')]
    elif conf_dict['probe_default']:
        probes = [probe.strip() for probe in conf_dict['probe_default'].split(',')]
    else:
        probes.append(PROBE)

    # 获取探针 payload
    probes_payload = {}
    payload_path = os.path.join(script_rel_dir, 'data', 'payload')
    for probe in probes:
        payload_file = os.path.join(payload_path, f'{probe}.txt')
        if check_file(payload_file):
            probes_payload[probe] = read_file(payload_file)

    # 初始化 OOB 检测器实例
    if oob_provider == 'ceye' and not (conf_dict['ceye_id'] and conf_dict['ceye_token']):
        print("[*] When using the ceye out-of-band service, you must configure the id and token. Now use dnslog as a backup.")
        oob_provider = 'dnslog'
    oob_detector = OOBDetector(oob_provider, proxies, timeout, conf_dict['ceye_id'], conf_dict['ceye_token'])
        
    # 设置 Chrome 参数
    browser = Browser(proxies, user_agent) if 'xss' in probes else None

    # 创建存储漏洞文件目录
    outputdir = options.output_dir if options.output_dir else os.path.join(script_rel_dir, 'output')
    os.makedirs(outputdir, exist_ok=True)

    # 将测试目标平台存储在环境变量
    os.environ['platform'] = conf_dict['misc_platform'].lower() if conf_dict['misc_platform'] else PLATFORM

    # 获取 requests 默认请求头
    default_headers = get_default_headers()

    # 初始请求对象
    init_request = {
        'url': '',
        'method': '',
        'params': {},
        'proxies': proxies,
        'cookies': {},
        'headers': default_headers,
        'data': {},
        'auth': {},
        'timeout': timeout
    }

    # 遍历检测 request
    # 计数
    req_total = 0
    with open(options.requests_file, 'r', encoding='utf-8') as f:
        orig_requests = json.load(f)
        for orig_request in orig_requests:
            req_total += 1
            method = orig_request.get('method')
            url = orig_request.get('url')
            print(f'[+] Start scanning url: {method} {url}')

            request = copy.deepcopy(init_request)

            # 方法
            request['method'] = method
            
            # URL
            o = urlparse(unquote(url))
            request['url'] = o._replace(fragment="")._replace(query="").geturl()

            # 查询字符串
            qs = parse_qsl(o.query)
            for par, val in qs:
                request['params'][par]=val

            # 请求头
            if orig_request.get('headers'):
                for name, value in orig_request.get('headers').items():
                    if name not in ['Cookie', 'User-Agent']:
                        request['headers'][name.lower()] = value

            # Cookie
            if orig_request.get('headers').get('Cookie'):
                for item in orig_request.get('headers').get('Cookie').split(';'):
                    name, value = item.split('=', 1)
                    request['cookies'][name.strip()] = unquote(value)

            # Data
            content_type = ''
            if request['method'] == 'POST' and orig_request.get('data'):
                data = base64.b64decode(orig_request.get('data')).decode('utf-8')
                full_content_type = request['headers']['content-type']

                if 'json' in full_content_type:
                    # json data
                    content_type = 'json'
                    request['data'] = json.loads(data)
                elif 'xml' in full_content_type:
                    # xml data
                    content_type = 'xml'
                    request['data'] = data
                elif 'form' in full_content_type:
                    # form data
                    content_type = 'form'
                    for item in data.split('&'):
                        name, value = item.split('=', 1)
                        request['data'][name.strip()] = unquote(value)
                else:
                    print('[*] post data is invalid, support form/json/xml data type')
                    continue

            # 指定 User-Agent
            request['headers']['user-agent'] = user_agent

            # 基准请求
            base_http = send_request(request, True)
            if base_http.get('status') not in [200, 301, 302, 307, 308]:
                print(f"[*] base request failed, status code is: {base_http.get('status')}")
                continue

            # 构造全部 request 对象（每个标记点对应一个对象）
            requests = []
            mark_request = copy.deepcopy(request)

            """
            以下情况不处理：
            1. 值为 Base64 字符串
            2. 名称被忽略
            """

            # 处理查询字符串
            for par, val in request['params'].items():
                if is_base64(val) or (par in ignore_params):
                    continue
                if get_content_type(val) == 'json':
                    # xxx.php?foo={"a":"b","c":"d"}&bar={"aa":"bb"}
                    val_dict = json.loads(val)
                    base_val_dict = copy.deepcopy(val_dict)
                    for k, v in val_dict.items():
                        if type(v) is not str or is_base64(v) or (k in ignore_params):
                            continue

                        base_val_dict[k] = v + MARK_POINT
                        mark_request['params'][par] = json.dumps(base_val_dict)
                        requests.append(copy.deepcopy(mark_request))
                        base_val_dict[k] = v
                else:
                    mark_request['params'][par] = val + MARK_POINT
                    requests.append(copy.deepcopy(mark_request))
                mark_request['params'][par] = request['params'][par]

            # 处理 Cookie
            for name, value in request['cookies'].items():
                if is_base64(value) or (name in ignore_params):
                    continue
                mark_request['cookies'][name] = value + MARK_POINT
                requests.append(copy.deepcopy(mark_request))
                mark_request['cookies'][name] = value

            # 处理 POST Body
            if content_type == 'xml':
                # xml data
                xmlTree = ET.ElementTree(ET.fromstring(request['data']))

                tagList = [elem.tag \
                    if re.search(fr'<{elem.tag}>[^<>]*</{elem.tag}>', request['data']) \
                    else None \
                    for elem in xmlTree.iter()]
                # 移除重复元素 tag 和 None 值
                tagList = list(set(list(filter(None, tagList))))
                tagList.sort()

                for elem_tag in tagList:
                    mark_request['data'] = re.sub(fr'<{elem_tag}>[^<>]*</{elem_tag}>', f'<{elem_tag}>{MARK_POINT}</{elem_tag}>', request['data'])
                    requests.append(copy.deepcopy(mark_request))
                mark_request['data'] = request['data']
            else:
                for field, value in request['data'].items():
                    if type(value) is not str or is_base64(value) or (field in ignore_params):
                        continue
                    mark_request['data'][field] = value + MARK_POINT
                    requests.append(copy.deepcopy(mark_request))
                    mark_request['data'][field] = value

            # 处理请求头
            for name, value in request['headers'].items():
                # 目前只处理 Referer 和 User-Agent
                if name not in {'referer', 'user-agent'}:
                    continue
                mark_request['headers'][name] = value + MARK_POINT
                requests.append(copy.deepcopy(mark_request))
                mark_request['headers'][name] = value

            # request 对象列表
            if not requests:
                print("[+] Not valid request object to fuzzing, Exit.")
                continue

            # 开始检测
            fuzz_results = []
            fuzz_results.extend(Fuzzer(requests, base_http, probes, probes_payload, oob_detector, browser).run())

            # 记录漏洞
            if fuzz_results:
                outputfile = os.path.join(outputdir, f'vuls_{time.strftime("%Y%m%d%H%M%S")}.txt')
                with open(outputfile, 'w') as f:
                    for result in fuzz_results:
                        f.write(json.dumps(result)+'\n')
                print(f'[+] Fuzz results saved in: {outputfile}')

            print('\n -------------------------------------------- \n')

            time.sleep(1)

    print(f"\n\n[+] Fuzz finished, {req_total} urls scanned in {int(time.time()) - start_time} seconds.")
